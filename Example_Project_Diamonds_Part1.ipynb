{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diamonds Data Exploration\n",
    "\n",
    "## Preliminary Wrangling\n",
    "\n",
    "This document explores a dataset containing prices and attributes for approximately 54,000 round-cut diamonds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dataset into a pandas dataframe, print statistics\n",
    "diamonds = pd.read_csv('diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 10)\n",
      "carat      float64\n",
      "cut         object\n",
      "color       object\n",
      "clarity     object\n",
      "depth      float64\n",
      "table      float64\n",
      "price        int64\n",
      "x          float64\n",
      "y          float64\n",
      "z          float64\n",
      "dtype: object\n",
      "   carat        cut color clarity  depth  table  price     x     y     z\n",
      "0   0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
      "1   0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
      "2   0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
      "3   0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
      "4   0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
      "5   0.24  Very Good     J    VVS2   62.8   57.0    336  3.94  3.96  2.48\n",
      "6   0.24  Very Good     I    VVS1   62.3   57.0    336  3.95  3.98  2.47\n",
      "7   0.26  Very Good     H     SI1   61.9   55.0    337  4.07  4.11  2.53\n",
      "8   0.22       Fair     E     VS2   65.1   61.0    337  3.87  3.78  2.49\n",
      "9   0.23  Very Good     H     VS1   59.4   61.0    338  4.00  4.05  2.39\n"
     ]
    }
   ],
   "source": [
    "# high-level overview of data shape and composition\n",
    "print(diamonds.shape)\n",
    "print(diamonds.dtypes)\n",
    "print(diamonds.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cut, color, and clarity into ordered categorical types\n",
    "ordinal_var_dict = {'cut': ['Fair','Good','Very Good','Premium','Ideal'],\n",
    "                    'color': ['J', 'I', 'H', 'G', 'F', 'E', 'D'],\n",
    "                    'clarity': ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']}\n",
    "\n",
    "for var in ordinal_var_dict:\n",
    "    ordered_var = pd.api.types.CategoricalDtype(ordered = True,\n",
    "                                                categories = ordinal_var_dict[var])\n",
    "    diamonds[var] = diamonds[var].astype(ordered_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              carat         depth         table         price             x  \\\n",
      "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
      "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
      "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
      "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
      "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
      "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
      "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
      "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
      "\n",
      "                  y             z  \n",
      "count  53940.000000  53940.000000  \n",
      "mean       5.734526      3.538734  \n",
      "std        1.142135      0.705699  \n",
      "min        0.000000      0.000000  \n",
      "25%        4.720000      2.910000  \n",
      "50%        5.710000      3.530000  \n",
      "75%        6.540000      4.040000  \n",
      "max       58.900000     31.800000  \n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics for numeric variables\n",
    "print(diamonds.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "There are 53,940 diamonds in the dataset with 10 features (carat, cut, color, clarity, depth, table, price, x, y, and z). Most variables are numeric in nature, but the variables cut, color, and clarity are ordered factor variables with the following levels.\n",
    "\n",
    "(worst) ——> (best) <br>\n",
    "cut: Fair, Good, Very Good, Premium, Ideal <br>\n",
    "color: J, I, H, G, F, E, D <br>\n",
    "clarity: I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "I'm most interested in figuring out what features are best for predicting the price of the diamonds in the dataset.\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "I expect that carat will have the strongest effect on each diamond's price: the larger the diamond, the higher the price. I also think that the other big \"C\"s of diamonds: cut, color, and clarity, will have effects on the price, though to a much smaller degree than the main effect of carat.\n",
    "\n",
    "## Univariate Exploration\n",
    "\n",
    "I'll start by looking at the distribution of the main variable of interest: price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a standard-scaled plot\n",
    "binsize = 500\n",
    "bins = np.arange(0, diamonds['price'].max()+binsize, binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = diamonds, x = 'price', bins = bins)\n",
    "plt.xlabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a long tail in the distribution, so let's put it on a log scale instead\n",
    "log_binsize = 0.025\n",
    "bins = 10 ** np.arange(2.4, np.log10(diamonds['price'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = diamonds, x = 'price', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([500, 1e3, 2e3, 5e3, 1e4, 2e4], [500, '1k', '2k', '5k', '10k', '20k'])\n",
    "plt.xlabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price has a long-tailed distribution, with a lot of diamonds on the low price end, and few on the high price end. When plotted on a log-scale, the price distribution looks roughly bimodal, with one peak between 500 and 1000, and a second peak a little below 5000. Interestingly, there's a steep jump in frequency right before 2000, rather than a smooth ramp up.\n",
    "\n",
    "Next up, the first predictor variable of interest: carat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting carat on a standard scale\n",
    "binsize = 0.05\n",
    "bins = np.arange(0, diamonds['carat'].max()+binsize, binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = diamonds, x = 'carat', bins = bins)\n",
    "plt.xlim([0,3.5])\n",
    "plt.xlabel('Carat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating further on an even smaller bin size\n",
    "binsize = 0.01\n",
    "bins = np.arange(0.2, 1.51, 0.01)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = diamonds, x = 'carat', bins = bins)\n",
    "plt.xlim([0.2,1.5])\n",
    "plt.xlabel('Carat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of carat, the small bin size proves very illuminating. There are very large spikes in frequency at the bars with one digit of precision (e.g. 0.3, 0.7, 1.0); frequency quickly trails off until the next spike. These probably represent standard diamond sizes for use in jewelry.\n",
    "\n",
    "I'll now move on to the other 'c' variables in the dataset: cut, color, and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot all three together to get an idea of each ordinal variable's distribution.\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, figsize = [8,8])\n",
    "\n",
    "default_color = sb.color_palette()[0]\n",
    "sb.countplot(data = diamonds, x = 'cut', color = default_color, ax = ax[0])\n",
    "sb.countplot(data = diamonds, x = 'color', color = default_color, ax = ax[1])\n",
    "sb.countplot(data = diamonds, x = 'clarity', color = default_color, ax = ax[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cut quality of the diamonds in the dataset is generally quite good, with most of them in the Premium or Ideal level. Most of the diamonds are also of color quality G or better. Clarity, shows a trend opposite from the other two features, with most of the diamonds on the lower end of the scale, at VS2 or worse. Clarity grades become rarer as steps are taken up the scale.\n",
    "\n",
    "I'll now look at the other features in the data to see if any of them hold interesting properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with the major dimensions of the diamonds, with x, y, and z.\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, figsize = [8,8])\n",
    "\n",
    "variables = ['x', 'y', 'z']\n",
    "for i in range(len(variables)):\n",
    "    var = variables[i]\n",
    "    bins = np.arange(min(diamonds[var]), max(diamonds[var])+0.2, 0.2)\n",
    "    ax[i].hist(data = diamonds, x = var, bins = bins)\n",
    "    ax[i].set_xlabel('{} (mm)'.format(var))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial plot of the x, y, and z features show some immediate points of attention. On the y and z plots, most of the data is set to the far left of their axes, suggesting some strong outliers on the right. The left limits of all three plots also suggest that there are some points that take unusually small values. It's worth taking a bit of time to identify these outliers and see if they need to be filtered out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select low outliers, using criteria eyeballed from the plots\n",
    "\n",
    "low_outliers = (diamonds['x'] < 3.5) | (diamonds['y'] < 3.5) | (diamonds['z'] < 2)\n",
    "\n",
    "print(low_outliers.sum())\n",
    "print(diamonds.loc[low_outliers,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 23 outliers with unusually low values for x, y, or z. Most of them have a 0 value for z, some of them also have a 0 value for x or y. The three diamonds that don't have a 0 value have a z-value that actually matches their carat instead. There might have been an error in data input. Interestingly, these diamonds tend to be fairly high in price, most of them above the median and over half above the third quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select high outliers, using criteria eyeballed from the plots\n",
    "\n",
    "high_outliers = ((diamonds['y'] > 10) | (diamonds['z'] > 6))\n",
    "print(high_outliers.sum())\n",
    "print(diamonds.loc[high_outliers,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the high outliers appear to be valid points, with the exception of the three points with extreme values in the y and z variables. As a final outlier check, since 'table' is the ratio of z to the average of x and y ((2\\*z)/(x+y)), we can see how many points do not have a matching calculated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select points whose depth value does not match x, y, and z values.\n",
    "\n",
    "incorrect_depth = (np.abs(2 * diamonds['z'] / (diamonds['x'] + diamonds['y']) - diamonds['depth']/100) > 0.1)\n",
    "no_size_info = ((diamonds['x'] == 0) & (diamonds['y'] == 0))\n",
    "print(diamonds.loc[incorrect_depth | no_size_info,['carat','depth','x','y','z']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This check captures not only the 26 outliers that were identified above, but a number of other points that had conflicting information. For safety, I'll remove all of these inconsistent points from the data. Then, I'll recreate the plots of x, y, and z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove points with inconsistent depth values.\n",
    "diamonds = diamonds.loc[-incorrect_depth & -no_size_info,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-plot the distribution of x, y, and z.\n",
    "fig, ax = plt.subplots(nrows=3, figsize = [8,8])\n",
    "\n",
    "variables = ['x', 'y', 'z']\n",
    "for i in range(len(variables)):\n",
    "    var = variables[i]\n",
    "    bins = np.arange(min(diamonds[var]), max(diamonds[var])+0.1, 0.1)\n",
    "    ax[i].hist(data = diamonds, x = var, bins = bins)\n",
    "    ax[i].set_xlabel('{} (mm)'.format(var))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the shape of the x, y, and z distributions are very similar to one another. The z distribution just looks slightly different since it takes a smaller range of values, and so the bins are larger in a relative sense. It's likely that these variables will be highly correlated with one another, and probably have a strong correlation with carat.\n",
    "\n",
    "Before closing this section, we'll take a look at the last two variables: depth and table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-using code to plot depth and table.\n",
    "fig, ax = plt.subplots(nrows=2, figsize = [9,8])\n",
    "\n",
    "variables = ['table', 'depth']\n",
    "for i in range(len(variables)):\n",
    "    var = variables[i]\n",
    "    bins = np.arange(min(diamonds[var]), max(diamonds[var])+0.2, 0.2)\n",
    "    ax[i].hist(data = diamonds, x = var, bins = bins)\n",
    "    ax[i].set_xlabel('{}'.format(var))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both table and depth are unimodal, but the distributions are slightly skewed and look a little narrower than a normal distribution. Table is slightly skewed right, while depth is slightly skewed left; I wonder if they're negatively correlated. Table is also a discrete numeric variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "The price variable took on a large range of values, so I looked at the data using a log transform. Under the transformation, the data looked bimodal, with one peak between \\$500 and \\$1000, and another just below \\$5000.\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "When investigating the x, y, and z size variables, a number of outlier points were identified. Overall, these points can be characterized by an inconsistency between the recorded value of depth, and the value that would be derived from using x, y, and z. For safety, all of these points were removed from the dataset to move forwards.\n",
    "\n",
    "## Bivariate Exploration\n",
    "\n",
    "To start off with, I want to look at the pairwise correlations present between features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = ['price', 'carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "categoric_vars = ['cut', 'color', 'clarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "plt.figure(figsize = [8, 5])\n",
    "sb.heatmap(diamonds[numeric_vars].corr(), annot = True, fmt = '.3f',\n",
    "           cmap = 'vlag_r', center = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrix: sample 500 diamonds so that plots are clearer and they render faster\n",
    "print(\"diamonds.shape=\",diamonds.shape)\n",
    "diamonds_samp = diamonds.sample(n=500, replace = False)\n",
    "print(\"diamonds_samp.shape=\",diamonds_samp.shape)\n",
    "\n",
    "g = sb.PairGrid(data = diamonds_samp, vars = numeric_vars)\n",
    "g = g.map_diag(plt.hist, bins = 20);\n",
    "g.map_offdiag(plt.scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the 'x', 'y', and 'z' dimensions are all highly correlated with one another, and all of them are also highly correlated with carat. Since carat is a measure of diamond size, it's not too surprising that the overall trend between carat and the three individual dimensions appears polynomial. In addition, since all the diamonds are round-cut, it makes sense that the 'x', 'y', and 'z' sizes would all move proportionally together.\n",
    "\n",
    "Surprisingly, the correlation coefficient between price and carat is very high, despite the fact that price has such a large range of values. This will be worth extra exploration in this section. Depth and table don't have strong correlations with any other numeric variables in the dataset, and we see the moderate negative correlation hypothesized in the previous section. I won't perform any further analyses with these variables since they don't look like they'll be of much further interest.\n",
    "\n",
    "Let's move on to looking at how price and carat weight correlate with the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrix of numeric features against categorical features.\n",
    "# can use a larger sample since there are fewer plots and they're simpler in nature.\n",
    "\n",
    "# Deprecated\n",
    "# samples = np.random.choice(diamonds.shape[0], 2000, replace = False)\n",
    "# diamonds_samp = diamonds.loc[samples,:]\n",
    "\n",
    "diamonds_samp = diamonds.sample(n=2000, replace = False)\n",
    "\n",
    "\n",
    "def boxgrid(x, y, **kwargs):\n",
    "    \"\"\" Quick hack for creating box plots with seaborn's PairGrid. \"\"\"\n",
    "    default_color = sb.color_palette()[0]\n",
    "    sb.boxplot(x=x, y=y, color=default_color)\n",
    "\n",
    "plt.figure(figsize = [10, 10])\n",
    "g = sb.PairGrid(data = diamonds_samp, y_vars = ['price', 'carat'], x_vars = categoric_vars,\n",
    "                height = 3, aspect = 1.5)\n",
    "g.map(boxgrid)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it appears that there are some negative relationships between the categorical variables and the two numeric variables of interest. The diamonds with the best features (Ideal cut, color D, clarity IF) seem to get the lowest prices, but also tend to be smaller on average. This will be worth investigating more later on, using the full data.\n",
    "\n",
    "Finally, let's look at relationships between the three categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there's only three subplots to create, using the full data should be fine.\n",
    "plt.figure(figsize = [8, 8])\n",
    "\n",
    "# subplot 1: color vs cut\n",
    "plt.subplot(3, 1, 1)\n",
    "sb.countplot(data = diamonds, x = 'color', hue = 'cut', palette = 'Blues')\n",
    "\n",
    "# subplot 2: clarity vs. cut\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "sb.countplot(data = diamonds, x = 'clarity', hue = 'cut', palette = 'Blues')\n",
    "ax.legend(ncol = 2) # re-arrange legend to reduce overlapping\n",
    "\n",
    "# subplot 3: clarity vs. color, use different color palette\n",
    "ax = plt.subplot(3, 1, 3)\n",
    "sb.countplot(data = diamonds, x = 'clarity', hue = 'color', palette = 'Greens')\n",
    "ax.legend(loc = 1, ncol = 2) # re-arrange legend to remove overlapping\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be that much interaction between diamond color and cut, though proportionally it seems like there might be more \"Very Good\" and \"Premium\" diamonds on the better color grades (F, E, and D). There are slightly larger interactions on the clarity grades, especially the lower levels of SI2, SI1, and VS2. It looks like there are more Very Good and Premium cut diamonds and more G, F, and E color diamonds compared to higher clarity grades.\n",
    "\n",
    "With the preliminary look at bivariate relationships out of the way, I want to dig into some of the relationships more. First, I want to see how price and carat are related to one another for all of the data, and to plot price on a log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of price vs. carat, with log transform on price axis\n",
    "\n",
    "plt.figure(figsize = [8, 6])\n",
    "plt.scatter(data = diamonds, x = 'carat', y = 'price', alpha = 1/10)\n",
    "plt.xlim([0, 3.5])\n",
    "plt.xlabel('Carat')\n",
    "plt.yscale('log')\n",
    "plt.yticks([500, 1e3, 2e3, 5e3, 1e4, 2e4], [500, '1k', '2k', '5k', '10k', '20k'])\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot suggests from the concavity that we might want to also transform the 'carat' variable to see a linear\n",
    "trend. There also appears to be a price ceiling in the data: given the spread of prices for carat values less than 1.5, we'd expect the prices to be more spread out for carat sizes greater than 1.5 and to see diamonds of value higher than $20k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since x, y, and z have a polynomial relationship with carat, let's see how\n",
    "# one of them correlates with price.\n",
    "plt.figure(figsize = [8, 6])\n",
    "plt.scatter(data = diamonds, x = 'z', y = 'price', alpha = 1/10)\n",
    "plt.xlabel('z (mm)')\n",
    "plt.yscale('log')\n",
    "plt.yticks([500, 1e3, 2e3, 5e3, 1e4, 2e4], [500, '1k', '2k', '5k', '10k', '20k'])\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting one of the size dimensions against price generates a relationship that looks much more linear. I'll write a function to perform the cube root and its inverse (just cubing) so I can create this kind of plot on carat. Carat is preferable to 'x', 'y', or 'z' for its general audience interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuberoot_trans(x, inverse = False):\n",
    "    \"\"\" quick function for computing cube root and cube operations \"\"\"\n",
    "    if not inverse:\n",
    "        return x ** (1/3)\n",
    "    else:\n",
    "        return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of price vs. carat, with log transform on price axis and\n",
    "# cube-root transform on price\n",
    "diamonds['cr_carat'] = diamonds['carat'].apply(cuberoot_trans)\n",
    "\n",
    "plt.figure(figsize = [8, 6])\n",
    "plt.scatter(data = diamonds, x = 'cr_carat', y = 'price', alpha = 1/10)\n",
    "\n",
    "carat_ticks = [0.2, 0.3, 0.5, 0.7, 1, 1.5, 2, 3]\n",
    "plt.xticks(cuberoot_trans(np.array(carat_ticks)), carat_ticks)\n",
    "plt.xlim([cuberoot_trans(.18), cuberoot_trans(3.5)])\n",
    "plt.xlabel('Carat')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.yticks([500, 1e3, 2e3, 5e3, 1e4, 2e4], [500, '1k', '2k', '5k', '10k', '20k'])\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a second look at the price and carat distributions on the three categorical variables: cut, color, and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the logarithm of price to make multivariate plotting easier\n",
    "def log_trans(x, inverse = False):\n",
    "    \"\"\" quick function for computing log and power operations \"\"\"\n",
    "    if not inverse:\n",
    "        return np.log10(x)\n",
    "    else:\n",
    "        return np.power(10, x)\n",
    "\n",
    "diamonds['log_price'] = diamonds['price'].apply(log_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the categorical variables against price and carat again, this time\n",
    "# with full data and variable transforms\n",
    "fig, ax = plt.subplots(ncols = 2, nrows = 3 , figsize = [10,10])\n",
    "\n",
    "for i in range(len(categoric_vars)):\n",
    "    var = categoric_vars[i]\n",
    "    sb.violinplot(data = diamonds, x = var, y = 'log_price', ax = ax[i,0],\n",
    "               color = default_color)\n",
    "    ax[i,0].set_yticks(log_trans(np.array([500, 1e3, 2e3, 5e3, 1e4, 2e4])))\n",
    "    ax[i,0].set_yticklabels([500, '1k', '2k', '5k', '10k', '20k'])\n",
    "    sb.violinplot(data = diamonds, x = var, y = 'cr_carat', ax = ax[i,1],\n",
    "               color = default_color)\n",
    "    ax[i,1].set_yticks(cuberoot_trans(np.array(carat_ticks)))\n",
    "    ax[i,1].set_yticklabels(carat_ticks)\n",
    "    ax[i,1].set_ylim(cuberoot_trans(np.array([0.1, 3.5])))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of the full data using a violin plot and variable transformations reveals much more than the earlier box plots. It is highly suggested that the decrease in average price across increasing quality is due to the average diamond size decreasing with increasing quality. This is clearest in the plots across clarity, moderately visible with cut, and least evident with color. It will be interesting to see how the categories map in the multivariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "Price had a surprisingly high amount of correlation with the diamond size, even before transforming the features. An approximately linear relationship was observed when price was plotted on a log scale and carat was plotted with a cube-root transform. The scatterplot that came out of this also suggested that there was an upper bound on the diamond prices available in the dataset, since the range of prices for the largest diamonds was much narrower than would have been expected, based on the price ranges of smaller diamonds.\n",
    "\n",
    "There was also an interesting relationship observed between price and the categorical features. For all of cut, color, and clarity, lower prices were associated with increasing quality. One of the potentially major interacting factors is the fact that improved quality levels were also associated with smaller diamonds. This will have to be explored further in the next section.\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "Expected relationships were found in the association between the 'x', 'y', and 'z' measurements of diamonds to the other linear dimensions as well as to the 'carat' variable. A small negative correlation was observed between table size and depth, but neither of these variables show a strong correlation with price, so they won't be explored further. There was also a small interaction in the categorical quality features. Diamonds of lower clarity appear to have slightly better cut and color grades.\n",
    "\n",
    "\n",
    "## Multivariate Exploration\n",
    "\n",
    "The main thing I want to explore in this part of the analysis is how the three categorical measures of quality play into the relationship between price and carat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist2dgrid(x, y, **kwargs):\n",
    "    \"\"\" Quick hack for creating heat maps with seaborn's PairGrid. \"\"\"\n",
    "    palette = kwargs.pop('color')\n",
    "    bins_x = np.arange(cuberoot_trans(.2), cuberoot_trans(3.5)+.05, .05)\n",
    "    bins_y = np.arange(2.4, 4.3+0.1, 0.1)\n",
    "    plt.hist2d(x, y, bins = [bins_x, bins_y], cmap = palette, cmin = 0.5)\n",
    "    plt.xticks(cuberoot_trans(np.array(carat_ticks)), carat_ticks)\n",
    "    plt.yticks(log_trans(np.array([500, 1e3, 2e3, 5e3, 1e4, 2e4])),\n",
    "               [500, '1k', '2k', '5k', '10k', '20k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faceted heat maps on levels of the cut variable\n",
    "g = sb.FacetGrid(data = diamonds, col = 'cut', col_wrap = 3, height = 3,\n",
    "                 xlim = [cuberoot_trans(.18), cuberoot_trans(3.5)])\n",
    "g.map(hist2dgrid, 'cr_carat', 'log_price', color = 'inferno_r')\n",
    "g.set_xlabels('Carat')\n",
    "g.set_ylabels('Price ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faceted heat maps on levels of the color variable\n",
    "g = sb.FacetGrid(data = diamonds, col = 'color', col_wrap = 4, height = 3,\n",
    "                 xlim = [cuberoot_trans(.18), cuberoot_trans(3.5)])\n",
    "g.map(hist2dgrid, 'cr_carat', 'log_price', color = 'inferno_r')\n",
    "g.set_xlabels('Carat')\n",
    "g.set_ylabels('Price ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faceted heat maps on levels of the clarity variable\n",
    "g = sb.FacetGrid(data = diamonds, col = 'clarity', col_wrap = 4, height = 3,\n",
    "                 xlim = [cuberoot_trans(.18), cuberoot_trans(3.5)])\n",
    "g.map(hist2dgrid, 'cr_carat', 'log_price', color = 'inferno_r')\n",
    "g.set_xlabels('Carat')\n",
    "g.set_ylabels('Price ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each of the faceted heat maps, you can see the relationship of quality level against price and diamond size, to varying levels of effectiveness. As the quality level increases, the 'cloud' of points moves towards the upper left of the plot, thus showing increased prices but also smaller diamonds. This is clearest in the clarity plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faceted heat maps on levels of cut and clarity\n",
    "g = sb.FacetGrid(data = diamonds, col = 'cut', row = 'clarity', size = 2.5,\n",
    "                 xlim = [cuberoot_trans(.18), cuberoot_trans(3.5)], margin_titles = True)\n",
    "g.map(hist2dgrid, 'cr_carat', 'log_price', color = 'inferno_r')\n",
    "g.set_xlabels('Carat')\n",
    "g.set_ylabels('Price ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried looking at a faceted heat map across two quality dimensions, but it seems like there's too many facets to look at. Perhaps a better summary can come from looking at only diamonds of a specific carat size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select diamonds of approximately 1 carat\n",
    "diamond_flag = (diamonds['carat'] >= 0.99) & (diamonds['carat'] <= 1.03)\n",
    "diamonds_1c = diamonds.loc[diamond_flag,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [8,6])\n",
    "ax = sb.pointplot(data = diamonds_1c, x = 'clarity', y = 'price', hue = 'cut',\n",
    "           palette = 'Blues', linestyles = '', dodge = 0.4)\n",
    "plt.title('1-carat diamond prices across cut and clarity')\n",
    "plt.ylabel('Mean Price ($)')\n",
    "plt.yscale('log')\n",
    "plt.yticks([2e3, 4e3, 6e3, 1e4], ['2k', '4k', '6k', '10k'])\n",
    "ax.set_yticklabels([],minor = True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dodged point plot for diamonds of approximately 1 carat in size shows the clear influence of clarity and cut on diamond price. The larger error bars on the right side are due to there being fewer diamonds at higher clarity grades at this diamond size. There also appear to be fewer diamonds of grade 'Fair' on the higher clarity grades, with none on the highest 'IF' rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select diamonds of approximately 0.3 carat\n",
    "diamond_flag = (diamonds['carat'] >= 0.29) & (diamonds['carat'] <= 0.33)\n",
    "diamonds_sml = diamonds.loc[diamond_flag,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [8,6])\n",
    "ax = sb.pointplot(data = diamonds_sml, x = 'clarity', y = 'price', hue = 'cut',\n",
    "           palette = 'Blues', linestyles = '', dodge = 0.4)\n",
    "plt.title('0.3-carat diamond prices across cut and clarity')\n",
    "plt.ylabel('Mean Price ($)')\n",
    "plt.yscale('log')\n",
    "plt.yticks([4e2, 6e2, 1e3], ['400', '600', '1000'])\n",
    "ax.set_yticklabels([],minor = True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot is less clear for the smaller diamonds around 0.3 carat. There are few diamonds in the lower clarity grades and more on the high-clarity grades at this diamond size. Interestingly, diamonds of the 'Fair' cut grade are generally higher-priced than the 'Good' and 'Very Good' cuts, but there's no good explanation for this from this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = [12,6])\n",
    "\n",
    "sb.pointplot(data = diamonds_sml, x = 'clarity', y = 'price', hue = 'color',\n",
    "             palette = 'Greens', linestyles = '', dodge = 0.4, ax = ax[0])\n",
    "ax[0].set_title('0.3-carat diamond prices across color and clarity')\n",
    "ax[0].set_ylabel('Mean Price ($)')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks([400, 600, 1000])\n",
    "ax[0].set_yticklabels(['400', '600', '1000'])\n",
    "ax[0].set_yticklabels([],minor = True)\n",
    "\n",
    "sb.pointplot(data = diamonds_1c, x = 'clarity', y = 'price', hue = 'color',\n",
    "             palette = 'Greens', linestyles = '', dodge = 0.4, ax = ax[1])\n",
    "ax[1].set_title('1-carat diamond prices across color and clarity')\n",
    "ax[1].set_ylabel('Mean Price ($)')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_yticks([2e3, 4e3, 6e3, 1e4])\n",
    "ax[1].set_yticklabels(['2k', '4k', '6k', '10k'])\n",
    "ax[1].set_yticklabels([],minor = True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hierarchy in pricing by color is clear when clustered across clarity values. The pattern looks more systematic than the \"cut by clarity\" pointplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "I extended my investigation of price against diamond size in this section by looking at the impact of the three categorical quality features. The multivariate exploration here showed that there indeed is a positive effect of increased quality grade on diamond price, but in the dataset, this is initially hidden by the fact that higher grades were more prevalent in smaller diamonds, which fetch lower prices overall. Controlling for the carat weight of a diamond shows the effect of the other C's of diamonds more clearly. This effect was clearest for the color and clarity variables, with less systematic trends for cut.\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "Looking back on the point plots, it doesn't seem like there's a systematic interaction effect between the three categorical features. However, the features also aren't fully independent. But it is interesting in something like the 1-carat plot for prices against cut and clarity, the shape of the 'cut' dots is fairly similar for the SI2 through VVS2 clarity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
